{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing Libraries: NumPy and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "![austin](http://www.austintexas.gov/sites/default/files/aac_logo.jpg)\n",
    "\n",
    "You have decided that you want to start your own animal shelter, but you want to get an idea of what that will entail to plan ahead. You have found out that Austin has one of the largest no-kill animal shelters in the country, and they keep meticulous track of animals that have been taken in and released. However, it is a large file, the online visualization tools provided are terrible, the data are recorded as strings, and the file holds an overwhelming amount of information. What can we do?\n",
    "\n",
    "\n",
    "#### Our goals today are to be able to: \n",
    "\n",
    "- Identify and import Python libraries\n",
    "- Identify differences between NumPy and base Python in usage and operation\n",
    "- Import/read data using Pandas\n",
    "- Identify Pandas objects and manipulate Pandas objects by index and columns\n",
    "- Filter data using Pandas\n",
    "\n",
    "#### Big questions for this lesson: \n",
    "\n",
    "- What is a package, what do packages do, and why might we want to use them?\n",
    "- When do we want to use NumPy versus Pandas?\n",
    "- What are the advantages of using Pandas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Things First\n",
    "\n",
    "![excel](excelpic.jpg)\n",
    "\n",
    "Why can't we just use Excel or Google Sheets? Let's discuss.\n",
    "\n",
    "Some resources/food for thought:\n",
    "\n",
    "- [Blog post 1](https://www.cbtnuggets.com/blog/certifications/microsoft/why-pandas-is-a-better-data-analysis-tool-than-excel)\n",
    "- [Blog post 2](https://blog.thedataincubator.com/2017/11/excel-and-pandas/)\n",
    "- [Blog post 3](https://towardsdatascience.com/intro-to-pandas-for-excel-super-users-dac1b38f12b0)\n",
    "- [And reddit weighs in on this topic, too](https://www.reddit.com/r/datascience/comments/8ggvx4/why_python_over_excel/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Python Libraries\n",
    "\n",
    "Alright, no matter where that discussion led and even if Excel has its uses, we still aren't going to use it in this course. But, before we dive into our animal data, we need to figure out how we're going to interact with our data. \n",
    "\n",
    "Do you remember that, in an earlier lesson, we wrote a function to calculate the mean of an list? That was **tedious**.\n",
    "\n",
    "Thankfully, other people have wrote and optimized functions and wrapped them into `libraries` we can then call and use in our analysis.\n",
    "\n",
    "![numpy](https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/numpy.png)\n",
    "\n",
    "[NumPy](https://www.numpy.org/) is the fundamental package for mathematic and scientific computing with Python. \n",
    "\n",
    "Let's use it! To import a package type `import` followed by the name of the library as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "\n",
    "x=numpy.array([1,2,3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#most packages have a standard way to import them\n",
    "import numpy as np\n",
    "\n",
    "y=np.array([4,5,6])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of numpy we can now get the **mean** and other quick math of lists and arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [4,3,25,40,62,20]\n",
    "print(np.mean(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import some other packages. We will cover in more detail some fun options for numpy later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes we will want to import a specific module from a library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR we can also import it this way\n",
    "\n",
    "from matplotlib import pyplot as plt \n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try importing the Seaborn library as ['sns'](https://en.wikipedia.org/wiki/Sam_Seaborn), which is the convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Seaborn here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we mess with naming conventions? For example, import one of our previous libraries as print.\n",
    "\n",
    "\n",
    "PLEASE NOTE THAT WE WILL HAVE TO RESET THE KERNEL AFTER RUNNING THIS. Comment out your code after running it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't say we didn't warn you\n",
    "\n",
    "#import numpy as print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Did we get an error? What about when we run the following command?\n",
    "\n",
    "print(x)\n",
    "\n",
    "# And now we all need to restart our kernels and clear cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpful links: library documenation\n",
    "\n",
    "Libraries have associated documentation to explain how to use the different tools included in a library. Reading documentation is an art, something we'll practice throughout this course, so don't worry too much if it doesn't feel natural yet (but let's discuss some tricks and tips for reading documentation outside of class if this isn't something you're used to yet!).\n",
    "\n",
    "- [NumPy](https://docs.scipy.org/doc/numpy/)\n",
    "- [SciPy](https://docs.scipy.org/doc/scipy/reference/)\n",
    "- [Pandas](http://pandas.pydata.org/pandas-docs/stable/)\n",
    "- [Matplotlib](https://matplotlib.org/contents.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. NumPy versus base Python\n",
    "\n",
    "Now that we know libraries exist, why do we want to use them? Let us examine a comparison between base Python and Numpy.\n",
    "\n",
    "Python has lists and base python can do basic math. NumPy, however, has the helpful objects called arrays.\n",
    "\n",
    "Numpy has a few advantages over base Python which we will look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a list in base Python\n",
    "names_list=['Bob','John','Sally']\n",
    "\n",
    "# Use numpy.array for numbers and numpy.char.array for strings\n",
    "names_array=np.char.array(['Bob','John','Sally']) \n",
    "\n",
    "print(names_list)\n",
    "print(names_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, let's make both a list and an array of three numbers\n",
    "num_list=[1, 2, 3]\n",
    "num_array=np.array([1, 2, 3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's divide the array by 2\n",
    "num_array/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But what if we want to divide the list by 2?\n",
    "num_list/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy arrays support the \\_div\\_ operator while python lists do not. There are other things that make it useful to utilize numpy over base python for evaluating data.\n",
    "\n",
    "Below, you will find a piece of code we will use to compare the speed of operations on a list and operations on an array. In this speed test, we will use the library [time](https://docs.python.org/3/library/time.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "size_of_vec = 100000\n",
    "\n",
    "def pure_python_version():\n",
    "    t1 = time.time()\n",
    "    X = range(size_of_vec)\n",
    "    Y = range(size_of_vec)\n",
    "    Z = [X[i] + Y[i] for i in range(len(X)) ]\n",
    "    return time.time() - t1\n",
    "\n",
    "def numpy_version():\n",
    "    t1 = time.time()\n",
    "    X = np.arange(size_of_vec)\n",
    "    Y = np.arange(size_of_vec)\n",
    "    Z = X + Y\n",
    "    return time.time() - t1\n",
    "\n",
    "\n",
    "t1 = pure_python_version()\n",
    "t2 = numpy_version()\n",
    "print(\"python: \" + str(t1), \"numpy: \"+ str(t2))\n",
    "print(\"Numpy is in this example \" + str(t1/t2) + \" times faster!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pairs, run the speed test with a different number, and share your results with the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Importing and reading data with ACTUAL LITERAL Pandas!\n",
    "\n",
    "\n",
    "![pandas-lib](https://pandas.pydata.org/_static/pandas_logo.png)\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/1600/1*oBx032ncOwLmCFX3Epo3Zg.jpeg \"https://cdn-images-1.medium.com/max/1600/1*oBx032ncOwLmCFX3Epo3Zg.jpeg\")\n",
    "\n",
    "#### Let's use Pandas to read some csv files so we can interact with them.\n",
    "\n",
    "First, let's check which directory we are in so the files we expect to see are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n",
    "!ls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember? It is possible to run terminal commands from jupyter notebook by using `!`\n",
    "\n",
    "Now, a csv file is one in which the data is separated by commas. Feel free to try to open this with a text editor, like TextEdit for Macs, to see what this looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# In order to read a csv file, we use pandas' read_csv function to read in the\n",
    "# csv as a pandas dataframe\n",
    "example_csv = pd.read_csv('example1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also `read_excel` and many other pandas `read` functions. Ever have a tsv (file with tab separated values)? You can still use `read_csv` - check out [the documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) for more details (yes those are a lot of arguments you can pass into that function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the head function to show the first 5 rows of a dataframe\n",
    "# This csv only has 2 rows, though\n",
    "example_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try loading in the example file in the directory called 'made_up_jobs.csv' using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in your csv here!\n",
    "\n",
    "# What do the first five rows look like?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also load in data by using the url of an associated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shelter_data = pd.read_csv(\n",
    "    'https://data.austintexas.gov/api/views/9t4d-g238/rows.csv?accessType=DOWNLOAD')\n",
    "# this link is copied directly from the download option for CSV\n",
    "\n",
    "shelter_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can read in data, let's get more comfortable with our Pandas data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(shelter_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out details about a specific column using brackets around the col name\n",
    "ID_series = shelter_data['Animal ID']\n",
    "\n",
    "type(ID_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Utilizing and identifying Pandas objects\n",
    "\n",
    "- What is a DataFrame object and what is a Series object? \n",
    "- How are they different from Python lists and dictionary objects?\n",
    "\n",
    "These are questions we will cover in this section. To start, let's start with this list of fruits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits = ['Apple','Orange','Watermelon','Lemon','Mango']\n",
    "\n",
    "print(fruits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our list of fruits, we can create a pandas object called a 'series' which is much like an array or a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits_series = pd.Series(fruits)\n",
    "\n",
    "print(fruits_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One difference between python **list objects** and pandas **series objects** is the fact that you can define the index _manually._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our index\n",
    "ind = ['a','a','c','d','e']\n",
    "\n",
    "# Now let's turn that into the index for that series\n",
    "fruits_series = pd.Series(fruits,index=ind)\n",
    "\n",
    "print(fruits_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .loc on a series to locate where the index matches what you pass in\n",
    "fruits_series.loc['a']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do a simliar thing with Python dictionaries. This time, however, we will create a DataFrame object from a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with list object in values\n",
    "student_dict = {\n",
    "    'name' : ['Samantha', 'Alex', 'Dante'],\n",
    "    'age' : ['35','17','26'],\n",
    "    'city' : ['Houston', 'Seattle', 'New York']\n",
    "}\n",
    "\n",
    "students_df = pd.DataFrame(student_dict)\n",
    "\n",
    "students_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find data types of values in columns\n",
    "# Note the lack of () - this is an attribute, not a method/function\n",
    "students_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the data type of ages to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note! df.colname is the same as df['colname']\n",
    "students_df.age = students_df['age'].astype(int)\n",
    "\n",
    "students_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use a custom index for these items. For example, we might want them to be the individual student ID numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_ids = ['1111','1145','0096']\n",
    "\n",
    "students_df = pd.DataFrame(student_dict,index=school_ids)\n",
    "\n",
    "students_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Pandas, we can also rename column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df.columns = ['NAME', 'AGE','HOME']\n",
    "students_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, we can also change the column names using the rename function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_df = students_df.rename(columns={'AGE': 'YEARS'})\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, there is a tool to remove rows and columns from your DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df.drop(columns=['AGE', 'HOME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Did that actually drop those columns? Let's do a sanity check\n",
    "students_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weird, those columns are still there! If you want the file to save over itself, use the option `inplace = True`.\n",
    "\n",
    "Every function has options. Let's read more about `drop` [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df.drop(index=['1111']) #unintuitively, this is a string!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding columns can be a bit trickier, however."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Started\n",
    "\n",
    "Let's define a function that returns a dataframe for us to work with. Note that this dataframe is created from a `list` of dictionaries, and each `dict` has identical _keys_ representing field names. The _values_ are the data to be stored in each field.\n",
    "\n",
    "This list-of-dictionaries format is a common way to represent _rows of data_ in Python.\n",
    "\n",
    "Pandas is not the only tool that supports it natively: **MongoDB** also represents each row of a dataset as a dictionary. This format is also useful when working with big data in Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_customer_data():\n",
    "    \"\"\"Return a Pandas DataFrame containing imaginary customer data.\"\"\"\n",
    "    customers = [\n",
    "        {'name': 'Harmony', 'state': 'OR'},\n",
    "        {'name': 'Sarah', 'state': 'CA'},\n",
    "        {'name': 'Sharad', 'state': 'WA'},\n",
    "        {'name': 'CJ', 'state': 'NY'},\n",
    "        {'name': 'Jerry', 'state': 'OR'},\n",
    "    ]\n",
    "    return pd.DataFrame(customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_customer_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the customer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = get_customer_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try to identify all Oregonian customers as hippies:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oregon_customer_df = customer_df.loc[customer_df['state'] == 'OR']\n",
    "oregon_customer_df['is_hippy'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try to identify all non-Oregonian customers as non-hippies:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_oregon_customer_df = customer_df[customer_df['state'] != 'OR']\n",
    "non_oregon_customer_df['is_hippy'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can do the same thing on a single line (and get the same warning):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df[customer_df['state'] == 'OR']['is_hippy'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See the results! (What's wrong?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What went wrong?\n",
    "\n",
    "1. First, we _sliced_ the original dataframe to include just Oregon customers.\n",
    "2. The _slice_ `oregon_customer_df` could be interpreted as a _new dataframe_ containing the selected rows in the original `customer_df`, or as a _pointer to_ the rows in the original dataframe. Pandas doesn't know which one we want.\n",
    "3. When we try to _modify_ or _set_ values in the slice, Pandas doesn't know what to do.\n",
    "\n",
    "#### One way to avoid the error is to explicitly make a copy of the slice with `df.copy()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oregon_customer_df = customer_df[customer_df['state'] == 'OR'].copy()\n",
    "oregon_customer_df['is_hippy'] = 1\n",
    "oregon_customer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What if we really want to modify the original dataframe?\n",
    "#### We can use `df.loc[columns, rows]` to explicity modify the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.loc[customer_df['state'] == 'OR', 'is_hippy'] = True\n",
    "customer_df.loc[customer_df['state'] != 'OR', 'is_hippy'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See the awesome results!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.dtypes\n",
    "\n",
    "\n",
    "customer_df['is_hippy'].astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Filtering data using Pandas\n",
    "\n",
    "There are several ways to grab particular data from a DataFrame.\n",
    "\n",
    "We saw the use of loc in the previous example. iloc and loc can be used in a few different ways to access data from a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.iloc[0] #returns the first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.iloc[:,0] #returns the first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.iloc[0:2] #returns first two rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.iloc[:,0:2] #returns the first two columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would we use indexing to return the last item in the last row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return the last item in the last row using indexing\n",
    "\n",
    "customer_df.iloc[-1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use loc to return rows and columns based on labels. Let's look at the students_df DataFrame again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df.loc['1111'] #returns the row associated with index 1111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df.loc[:,'YEARS'] #returns the column labeled 'YEARS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the row labeled '1111' for columns from 'NAME' to 'AGE'\n",
    "students_df.loc['1111','NAME':'AGE'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How could we return the first and last rows if `loc` accepts a list of labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return the first and last rows using one loc command\n",
    "students_df.iloc[[0,-1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use loc to complete more complicated filtering of our data using boolean indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns only rows where the name of the student is Samantha\n",
    "students_df.loc[students_df['NAME']=='Samantha'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also find out which customers in the customer_df DataFrame are not from Oregon. However, I only want to know their names. How would I return this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return the names of customers who are not from Oregon\n",
    "customer_df.loc[customer_df['state']!='OR']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select only a single column from a DataFrame. This will create a series, which allows for straightforwards, simple selection of the data it holds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states=customer_df.loc[:,'state'] #returns a series!!\n",
    "type(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states[0:3] #returns the first 3 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states[states=='OR'] #returns 'OR' data and index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to select specific data, we can manipulate those cells. For example, we need to update our customer data because all of our customers in Oregon have moved to New Jersey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.loc[customer_df[\"state\"]=='WA'] = 'NJ'\n",
    "\n",
    "customer_df\n",
    "# Is this what we want it to do? How should we change this\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or maybe we got a customer's name wrong and need to change that. Perhaps CJ is actually named TJ. How would we do that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return a the customer_df with the fixed name\n",
    "\n",
    "customer_df.loc[customer_df[\"name\"]=='CJ'] = 'TJ'\n",
    "\n",
    "customer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Recap/Further Practice\n",
    "\n",
    "Now that we have all of these new tools in our tool belt, let's dive into our animal shelter data! \n",
    "\n",
    "- Use `shelter_data.columns` to get the list of column names\n",
    "- Drop columns from the animal shelter data until you have only 5 columns remaining\n",
    "- Rename those columns\n",
    "- Get the `unique()` values in outcomes \n",
    "- select rows of animals based on an application of boolean indexing\n",
    "\n",
    "For extra credit: add in your own new column on information to this DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
